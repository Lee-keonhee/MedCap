import sys

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from transformers import GPT2Tokenizer, GPT2LMHeadModel
import argparse
from tqdm import tqdm

from src.data.dataset import ROCODataset
from src.data.preprocessing import load_roco_data
from src.models.multimodal_model import MultimodalModel
from src.utils.config import load_config

def collate_fn(batch, tokenizer):
    """
    ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬

    Args:
        batch: [(image, caption), (image, caption), ...]

    Returns:
        dict: {
            'images': tensor (B, 3, 224, 224),
            'input_ids': tensor (B, seq_len),
            'attention_mask': tensor (B, seq_len),
            'labels': tensor (B, seq_len)
        }
    """
    # TODO: imagesì™€ captions ë¶„ë¦¬
    images, captions = zip(*batch)

    # TODO: ì´ë¯¸ì§€ ìŠ¤íƒ
    images = torch.stack(images)

    # TODO: í…ìŠ¤íŠ¸ tokenization
    encoded = tokenizer(
        list(captions),
        padding=True,
        truncation=True,
        max_length=50,
        return_tensors='pt'
    )

    # TODO: labels ìƒì„± (input_idsì™€ ë™ì¼)
    labels = encoded['input_ids'].clone()

    # TODO: ë°˜í™˜
    return {
        'images': images,
        'input_ids': encoded['input_ids'],
        'attention_mask': encoded['attention_mask'],
        'labels': labels
    }
def train_epoch(model, dataloader, optimizer, device, epoch):
    """
        1 epoch í•™ìŠµ

        Args:
            model: ëª¨ë¸
            dataloader: ë°ì´í„°ë¡œë”
            optimizer: optimizer
            device: device
            epoch: í˜„ì¬ epoch

        Returns:
            float: í‰ê·  loss
    """
    model.train()
    total_loss = 0
    progress_bar = tqdm(dataloader, desc='Training')

    for batch in progress_bar:
        images = batch['images'].to(device)
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)


        optimizer.zero_grad()
        outputs = model(images=images,
                        input_ids=input_ids,
                        attention_mask=attention_mask,
                        labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        progress_bar.set_postfix({'train_loss' :f'{loss.item():.4f}'})
    epoch_loss = total_loss / len(dataloader)
    print(f'Epoch {epoch} | Train Loss: {epoch_loss}')
    return epoch_loss


def eval_epoch(model, dataloader, device, epoch):
    """
    Validation

    Args:
        model: ëª¨ë¸
        dataloader: validation ë°ì´í„°ë¡œë”
        device: device

    Returns:
        float: í‰ê·  validation loss
    """
    model.eval()
    total_loss = 0
    progress_bar = tqdm(dataloader, desc='Evaluating')
    with torch.no_grad():
        for batch in progress_bar:
            images = batch['images'].to(device)
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(images=images,
                            input_ids=input_ids,
                            attention_mask=attention_mask,
                            labels=labels)
            loss = outputs.loss
            total_loss += loss.item()
            progress_bar.set_postfix({'valid_loss' :f'{loss.item()}'})

        epoch_loss = total_loss / len(dataloader)
        print(f'Epoch {epoch} | Validation Loss: {epoch_loss:.4f}')
    return epoch_loss

def save_checkpoint(model, optimizer, epoch, loss, save_path):
    """
        Checkpoint ì €ì¥

        Args:
            model: ëª¨ë¸
            optimizer: optimizer
            epoch: í˜„ì¬ epoch
            loss: í˜„ì¬ loss
            save_path: ì €ì¥ ê²½ë¡œ
    """
    torch.save({'epoch': epoch,
                'state_dict': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'loss': loss},
               save_path)

def main(config):
    # device ì„¤ì •
    device = torch.device('cuda' if config['hardware']['device'] == 'cuda' else 'cpu')

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    train_data = load_roco_data(config['data']['raw_dir'],split='train')
    val_data = load_roco_data(config['data']['raw_dir'],split='validation')

    # ë°ì´í„° ì…‹ ìƒì„±
    train_dataset = ROCODataset(train_data,train=True,)
    val_dataset = ROCODataset(val_data,train=False,)

    # í† í¬ë‚˜ì´ì € ìƒì„± ë° pad_token ì„¤ì •
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    tokenizer.pad_token = tokenizer.eos_token

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(train_dataset,
                              batch_size=config['training']['batch_size'],
                              shuffle=True, num_workers=config['hardware']['num_workers'],
                              collate_fn=lambda x : collate_fn(x, tokenizer),
                              pin_memory=config['hardware']['pin_memory'])
    val_loader = DataLoader(val_dataset,
                            batch_size=config['validation']['batch_size'],
                            shuffle=False, num_workers=config['hardware']['num_workers'],
                            collate_fn=lambda x : collate_fn(x, tokenizer),
                            pin_memory=config['hardware']['pin_memory'])


    # ëª¨ë¸ ì„¤ì •
    model = MultimodalModel(vision_model=config['model']['vision_encoder']['name'],
                            language_model=config['model']['language_decoder']['name'],
                            pretrained=True,
                            image_feature_dim=config['model']['vision_encoder']['feature_dim'])
    model = model.to(device)
    print(f"\nUsing device: {device}")

    optimizer_name = config['training']['optimizer']['name']
    lr = float(config['training']['learning_rate'])

    # optimizer ì„¤ì •
    if optimizer_name == 'adamw':
        optimizer = optim.AdamW(model.parameters(), lr=lr)
    elif optimizer_name == 'adam':
        optimizer = optim.Adam(model.parameters(), lr=lr)
    elif optimizer_name == 'sgd':
        optimizer = optim.SGD(model.parameters(), lr=lr)
    else:
        raise ValueError(f'Unknown optimizer: {optimizer_name}')


    best_val_loss = float('inf')
    os.makedirs(config['logging']['save_dir'], exist_ok=True)
    loss_list = []
    patience = int(config['training']['early_stopping']['patience'])  # 5 epoch ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
    patience_counter = 0
    for epoch in range(config['training']['num_epochs']):
        train_loss = train_epoch(model, train_loader, optimizer, device, epoch)
        val_loss = eval_epoch(model, val_loader, device, epoch)

        if (epoch+1) % config['logging']['save_freq'] == 0:

            save_path = os.path.join(config['logging']['save_dir'],
                                     f"{config['experiment']['name']}_epoch{epoch+1}.pth"
                                     )
            save_checkpoint(model, optimizer, epoch, val_loss, save_path)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            best_path = os.path.join(
                config['logging']['save_dir'],f"{config['experiment']['name']}_best.pth"
            )
            torch.save(model.state_dict(), best_path)  # â† ëª¨ë¸ë§Œ!
            print(f"âœ… New best! Val Loss: {val_loss:.4f}\n")
        else:
            patience_counter += 1
            print(f"\nNo improvement for {patience_counter} epochs")

            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping at epoch {epoch}\n")
                break
if __name__ == '__main__':
    # print(torch.cuda.is_available())
    # íŒŒë¼ë¯¸í„° ì„¤ì • ë° parser ì„¤ì •
    os.chdir('../..')
    config_path = './configs/base_config.yaml'

    parser = argparse.ArgumentParser(description='Train a model with YAML config')
    parser.add_argument("--config",
                         type=str,
                         default=config_path,
                         help="config file path")

    parser.add_argument("--train_batch_size", type=int, default=None, help="Override training batch size")
    parser.add_argument("--val_batch_size", type=int, default=None, help="Override validation batch size")
    parser.add_argument("--learning_rate", type=float, default=None, help="Override training learning rate")
    parser.add_argument("--num_epochs", type=int, default=None, help="Override number of training epochs")
    parser.add_argument("--device", type=str, default=None, help="Override device (cpu/cuda)")

    args = parser.parse_args()

    config = load_config(config_path)

    if args.train_batch_size is not None:
        config["training"]["batch_size"] = args.train_batch_size
    if args.val_batch_size is not None:
        config["validation"]["batch_size"] = args.val_batch_size
    if args.learning_rate is not None:
        config["training"]["learning_rate"] = args.learning_rate
    if args.num_epochs is not None:
        config["training"]["num_epochs"] = args.num_epochs
    if args.device is not None:
        config["hardware"]["device"] = args.device

    main(config)