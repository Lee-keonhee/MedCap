import sys
sys.path.append('../')
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from transformers import GPT2Tokenizer

from src.data.dataset import ROCODataset
from src.data.preprocessing import load_roco_data
from src.models.multimodal_model import MultimodalModel


def check_overfitting(data_path):
    """
    ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ overfitting í…ŒìŠ¤íŠ¸
    ëª©í‘œ: Lossê°€ 0ì— ê°€ê¹Œì›Œì§€ëŠ”ì§€ í™•ì¸
    """

    # TODO: Step 1 - ë””ë°”ì´ìŠ¤ ì„¤ì •
    # - CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ 'cuda', ì•„ë‹ˆë©´ 'cpu'
    # - device ë³€ìˆ˜ì— ì €ì¥
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # TODO: Step 2 - ë°ì´í„° ì¤€ë¹„
    # - ROCO train ë°ì´í„° ë¡œë“œ (load_roco_data)
    # - ì²˜ìŒ 10ê°œë§Œ ì‚¬ìš© (ì‘ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸)
    data_list = load_roco_data(data_path, split='train')
    data_list = data_list[:10]

    # TODO: Step 3 - Tokenizer ì¤€ë¹„
    # - GPT2Tokenizer ë¡œë“œ
    # - pad_token ì„¤ì • (eos_tokenê³¼ ë™ì¼í•˜ê²Œ)
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    tokenizer.pad_token = tokenizer.eos_token


    # TODO: Step 4 - Collate function ì‘ì„±
    # - ë°°ì¹˜ ë‚´ ì´ë¯¸ì§€ë“¤ ìŠ¤íƒ
    # - í…ìŠ¤íŠ¸ë“¤ tokenization (padding=True, truncation=True, max_length=50)
    # - ë°˜í™˜: {'images': ..., 'input_ids': ..., 'attention_mask': ..., 'labels': ...}


    # TODO: Step 5 - Dataset & DataLoader
    # - ROCODataset ìƒì„± (train=True)
    # - DataLoader ìƒì„± (batch_size=2, collate_fn ì‚¬ìš©)
    train_dataset = ROCODataset(data_list, train=True,transform=None)
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: collate_fn(x, tokenizer))

    # TODO: Step 6 - ëª¨ë¸ ìƒì„±
    # - MultimodalModel ìƒì„±
    # - deviceë¡œ ì´ë™
    # - model.train() ëª¨ë“œ
    multimodal_model = MultimodalModel(vision_model='resnet50', language_model='gpt2', pretrained=True, image_feature_dim=2048)
    multimodal_model.to(device)

    # TODO: Step 7 - Optimizer ì„¤ì •
    # - Adam optimizer (lr=1e-4)
    optimizer = optim.Adam(multimodal_model.parameters(), lr=0.001)
    # TODO: Step 8 - Training Loop
    # - 100 iteration (ì‘ì€ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
    # - ë§¤ 10 iterationë§ˆë‹¤ loss ì¶œë ¥
    # - Lossê°€ ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸
    multimodal_model.train()
    for epoch in range(100):
        total_loss = 0
        for batch in train_loader:
            images, input_ids, attention, labels = batch['images'], batch['input_ids'], batch['attention_mask'], batch['labels']
            # print(images.shape)
            images = images.to(device)
            labels = labels.to(device)
            optimizer.zero_grad()
            outputs = multimodal_model(images=images,
                                       input_ids=input_ids,
                                       attention_mask=attention,
                                       labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        epoch_loss = total_loss / len(train_loader)
        if epoch % 10 ==0:
            print(f'Epoch {epoch} Loss: {epoch_loss}')





def collate_fn(batch, tokenizer):
    """
    ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬

    Args:
        batch: [(image, caption), (image, caption), ...]

    Returns:
        dict: {
            'images': tensor (B, 3, 224, 224),
            'input_ids': tensor (B, seq_len),
            'attention_mask': tensor (B, seq_len),
            'labels': tensor (B, seq_len)
        }
    """
    # TODO: imagesì™€ captions ë¶„ë¦¬
    images, captions = zip(*batch)

    # TODO: ì´ë¯¸ì§€ ìŠ¤íƒ
    images = torch.stack(images)

    # TODO: í…ìŠ¤íŠ¸ tokenization
    encoded = tokenizer(
        list(captions),
        padding=True,
        truncation=True,
        max_length=50,
        return_tensors='pt'
    )

    # TODO: labels ìƒì„± (input_idsì™€ ë™ì¼)
    labels = encoded['input_ids'].clone()

    # TODO: ë°˜í™˜
    return {
        'images': images,
        'input_ids': encoded['input_ids'],
        'attention_mask': encoded['attention_mask'],
        'labels': labels
    }


if __name__ == '__main__':
    data_path = './data/raw/ROCO/all_data'
    print("ğŸš€ Overfitting Test ì‹œì‘!")
    check_overfitting(data_path)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")